{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Logistic Regression","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"metadata":{"id":"WZarlp7aIBFO","colab_type":"text"},"cell_type":"markdown","source":["# ReadMe\n","\n","How to Setup:\n","\n","\n","*   Download the Casual and Professional datasets and change the \"professional_url\" variable to the path of the professional dataset, and change hte \"ranked_url\" variable to the path of the professional dataset.\n","*   For both professional and casual there are two different types of data, \"Vanilla\" and \"Winrates\". \"Vanilla\" for casual only have as features a one hot encoding of the champions played and the individual player skill levels. In the professional dataset it contains a one hot encoding of the champions played and a one hot encoding of the players on each team. For \"Winrates\" it contains the previously mentioned features, but in addition the compiled winrates for champion-champion matchups and individual champion winrates.\n","*   To switch between \"Winrates\" and \"Vanilla\", change the data_type to the appropriate string. To switch between the professional and casual dataset change casual to False or True respectively.\n","*   Set the batch size and number of epochs to run\n","\n","How to Run:\n","*   To run, simply set up as specified above and then run all code cells consecutively.\n","\n","Error Handling:\n","*    In the case of an error, reset the runtime and run the code cells consecutively again.\n","\n","\n"]},{"metadata":{"id":"t3NcpqeL29OP","colab_type":"code","colab":{}},"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import time\n","from sklearn import preprocessing\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.linear_model import LogisticRegressionCV\n","from sklearn.model_selection import train_test_split\n","from sklearn.feature_selection import RFE\n","from sklearn import metrics\n","import seaborn as sns\n","import matplotlib.pyplot as plt \n","from sklearn.model_selection import learning_curve\n","from sklearn.model_selection import ShuffleSplit\n","from sklearn.model_selection import validation_curve\n","from sklearn.decomposition import PCA\n","\n","from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"De5cQdRjIZnb","colab_type":"text"},"cell_type":"markdown","source":["# **Program Parameter Setup**"]},{"metadata":{"id":"WEY_nSgAIg6-","colab_type":"code","colab":{}},"cell_type":"code","source":["# Different data types are Vanilla and Winrates\n","data_type = \"Winrates\"\n","casual = True\n","PCA_on = False\n","professional_url = \"/content/gdrive/Team Drives/CIS 520/professional/\"\n","ranked_url = \"/content/gdrive/Team Drives/CIS 520/casual/\""],"execution_count":0,"outputs":[]},{"metadata":{"id":"ZfmD-nLMJwTo","colab_type":"code","colab":{}},"cell_type":"code","source":["def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n","                        n_jobs=None, train_sizes=np.linspace(.1, 1.0, 5)):\n","    plt.figure()\n","    plt.title(title)\n","    if ylim is not None:\n","        plt.ylim(*ylim)\n","    plt.xlabel(\"Training examples\")\n","    plt.ylabel(\"Score\")\n","    train_sizes, train_scores, test_scores = learning_curve(\n","        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n","    train_scores_mean = np.mean(train_scores, axis=1)\n","    train_scores_std = np.std(train_scores, axis=1)\n","    test_scores_mean = np.mean(test_scores, axis=1)\n","    test_scores_std = np.std(test_scores, axis=1)\n","    plt.grid()\n","\n","    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n","                     train_scores_mean + train_scores_std, alpha=0.1,\n","                     color=\"r\")\n","    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n","                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n","    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n","             label=\"Training score\")\n","    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n","             label=\"Cross-validation score\")\n","\n","    plt.legend(loc=\"best\")\n","    return plt"],"execution_count":0,"outputs":[]},{"metadata":{"id":"OtrKcabrNy2e","colab_type":"text"},"cell_type":"markdown","source":["# **Data Importing**"]},{"metadata":{"id":"XZBDfgBT4aIR","colab_type":"code","colab":{}},"cell_type":"code","source":["# Professional Data Import\n","\n","X_pro_filename_train = professional_url + \"train/Professional_Features_\" + data_type + \"_Train.csv\"\n","y_pro_filename_train = professional_url + \"train/Professional_Labels_Train.csv\"\n","X_pro_train = pd.read_csv(X_pro_filename_train)\n","y_pro_train = pd.read_csv(y_pro_filename_train)\n","\n","X_pro_filename_test = professional_url + \"test/Professional_Features_\" + data_type + \"_Test.csv\"\n","y_pro_filename_test = professional_url + \"test/Professional_Labels_Test.csv\"\n","X_pro_test = pd.read_csv(X_pro_filename_test)\n","y_pro_test = pd.read_csv(y_pro_filename_test)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"8L8uGiP7M69A","colab_type":"code","colab":{}},"cell_type":"code","source":["# Ranked Data Import\n","\n","X_ranked_filename_train = ranked_url + \"train/Casual_Features_\" + data_type + \"_Train.csv\"\n","y_ranked_filename_train = ranked_url + \"train/Casual_Labels_Train.csv\"\n","X_casual_train = pd.read_csv(X_ranked_filename_train)\n","y_casual_train = pd.read_csv(y_ranked_filename_train)\n","\n","X_ranked_filename_test = ranked_url + \"test/Casual_Features_\" + data_type + \"_Test.csv\"\n","y_ranked_filename_test = ranked_url + \"test/Casual_Labels_Test.csv\"\n","X_casual_test = pd.read_csv(X_ranked_filename_test)\n","y_casual_test = pd.read_csv(y_ranked_filename_test)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"JmRDDesXLKId","colab_type":"code","colab":{}},"cell_type":"code","source":["X_train = None\n","y_train = None\n","X_test = None\n","Y_test = None\n","if (not casual):\n","  X_train = X_pro_train\n","  y_train = y_pro_train\n","  X_test = X_pro_test\n","  y_test = y_pro_test\n","else:\n","  X_train = X_casual_train\n","  y_train = y_casual_train\n","  X_test = X_casual_test\n","  y_test = y_casual_test"],"execution_count":0,"outputs":[]},{"metadata":{"id":"uQocRppNNq8s","colab_type":"text"},"cell_type":"markdown","source":["# **Logistic Regression**"]},{"metadata":{"id":"wl4sOie6FHdG","colab_type":"code","colab":{}},"cell_type":"code","source":["# convert to categorical variables\n","\n","cat_vars = list(X_train)\n","\n","for var in cat_vars:\n","  if (\"winrate\" in var) or (\"player\" in var):\n","    continue\n","  else:\n","    X_train[var] = X_train[var].astype('category')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Rjlqlisp8zQm","colab_type":"code","colab":{}},"cell_type":"code","source":["# one-hot encoding\n","\n","cat_vars = list(X_train)\n","\n","split_at = X_train.shape[0]\n","full_data = X_train.append(X_test)\n","\n","for var in cat_vars:\n","  if (\"winrate\" in var) or (\"player\" in var):\n","    continue\n","  else:\n","    cat_list = pd.get_dummies(full_data[var], prefix = var) # makes every variable binary\n","    full_data = pd.concat([full_data, cat_list], axis=1)\n","\n","full_data.drop(columns = ['blue_top', 'red_top', 'blue_jungle', 'red_jungle', 'blue_middle','red_middle', 'blue_adc', 'red_adc', 'blue_support', 'red_support'], inplace=True)\n","  \n","X_train_encoded = full_data[0:split_at]\n","X_test_encoded = full_data[split_at:full_data.shape[0]]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"dYA0pT0vDcL6","colab_type":"code","colab":{}},"cell_type":"code","source":["# optional PCA\n","if PCA_on == True:\n","  components = 1\n","  variance_threshold = 0.9\n","  while True:\n","    pca = PCA(n_components=components)\n","    pca.fit(X_train_encoded)\n","    if np.sum(pca.explained_variance_ratio_) > variance_threshold:\n","      break\n","    else:\n","      components +=1\n","  X_train_encoded = pca.transform(X_train_encoded)\n","  X_test_encoded = pca.transform(X_test_encoded)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"X499K9ZG4iH6","colab_type":"code","colab":{}},"cell_type":"code","source":["# training the logistic regression model\n","# include cross-validation of L2 regularization parameter\n","\n","logreg = LogisticRegressionCV(Cs=10, cv=5, random_state=0, tol=0.001, max_iter=10000, solver='lbfgs')\n","start = time.time()\n","logreg.fit(X_train_encoded, np.ravel(y_train))\n","end = time.time()\n","print('Training Time: {:.5f}'.format(end - start))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ykq927pj5SCG","colab_type":"code","colab":{}},"cell_type":"code","source":["# predicting test set results and accuracy\n","\n","y_pred = logreg.predict(X_test_encoded)\n","print('Accuracy of logistic regression classifier on test set: {:.3f}'.format(logreg.score(X_test_encoded, y_test)))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Uoi4S-Nt5eFo","colab_type":"code","colab":{}},"cell_type":"code","source":["# confusion matrix\n","\n","from sklearn.metrics import confusion_matrix\n","confusion_matrix = confusion_matrix(y_test, y_pred)\n","print(confusion_matrix)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"jhhQUwpb5h2k","colab_type":"code","colab":{}},"cell_type":"code","source":["# metrics\n","\n","from sklearn.metrics import classification_report\n","print(classification_report(y_test, y_pred))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"NoQHOxVS5ksB","colab_type":"code","colab":{}},"cell_type":"code","source":["# ROC curve\n","\n","from sklearn.metrics import roc_auc_score\n","from sklearn.metrics import roc_curve\n","logit_roc_auc = roc_auc_score(y_test, logreg.predict(X_test_encoded))\n","fpr, tpr, thresholds = roc_curve(y_test, logreg.predict_proba(X_test_encoded)[:,1])\n","plt.figure()\n","plt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\n","plt.plot([0, 1], [0, 1],'r--')\n","plt.xlim([0.0, 1.0])\n","plt.ylim([0.0, 1.05])\n","plt.xlabel('False Positive Rate')\n","plt.ylabel('True Positive Rate')\n","plt.title('Receiver operating characteristic')\n","plt.legend(loc=\"lower right\")\n","plt.show()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"JXp3hiDLTy5b","colab_type":"code","colab":{}},"cell_type":"code","source":["# training the logistic regression model WITHOUT CV\n","C_selected = 1.0 / np.power(10,3)\n","logreg = LogisticRegression(random_state=0, tol=0.001, max_iter=10000, solver='lbfgs', penalty='l2', C=C_selected)\n","logreg.fit(X_train_encoded, np.ravel(y_train))\n","\n","# predicting test set results and accuracy\n","y_pred = logreg.predict(X_test_encoded)\n","print('Accuracy of logistic regression classifier on test set: {:.3f}'.format(logreg.score(X_test_encoded, y_test)))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"O6Qk35SnU3d7","colab_type":"code","colab":{}},"cell_type":"code","source":["# plots learning curve\n","title = r\"Logistic Regression Learning Curve after Cross-Validation\"\n","cv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)\n","estimator = logreg\n","plot_learning_curve(estimator, title, X_train_encoded, y_train, (0.9, 1.01), cv=cv, n_jobs=4)\n","\n","plt.show()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"pDuSxBDhW3XU","colab_type":"code","colab":{}},"cell_type":"code","source":["# CV curve logistic regression\n","cv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)\n","estimator = logreg\n","\n","param_range = np.logspace(-4, 2, 7)\n","train_scores, test_scores = validation_curve(estimator, X_train_encoded, np.ravel(y_train), param_name=\"C\", param_range=param_range,\n","    cv=5, scoring=\"accuracy\", n_jobs=1)\n","\n","train_scores_mean = np.mean(train_scores, axis=1)\n","train_scores_std = np.std(train_scores, axis=1)\n","test_scores_mean = np.mean(test_scores, axis=1)\n","test_scores_std = np.std(test_scores, axis=1)\n","\n","\n","plt.title(\"Logistic Regression Validation Curve\")\n","plt.xlabel(r\"$L2^{-1}$\")\n","plt.ylabel(\"Score\")\n","plt.ylim(0.9, 1.01)\n","#plt.ylim(0.4,0.8)\n","lw = 2\n","plt.semilogx(param_range, train_scores_mean, label=\"Training score\",\n","             color=\"darkorange\", lw=lw)\n","plt.fill_between(param_range, train_scores_mean - train_scores_std,\n","                 train_scores_mean + train_scores_std, alpha=0.2,\n","                 color=\"darkorange\", lw=lw)\n","plt.semilogx(param_range, test_scores_mean, label=\"Cross-validation score\",\n","             color=\"navy\", lw=lw)\n","plt.fill_between(param_range, test_scores_mean - test_scores_std,\n","                 test_scores_mean + test_scores_std, alpha=0.2,\n","                 color=\"navy\", lw=lw)\n","plt.legend(loc=\"best\")\n","plt.grid()\n","plt.show()"],"execution_count":0,"outputs":[]}]}