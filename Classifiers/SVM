{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"SVM","version":"0.3.2","provenance":[],"collapsed_sections":["KB032NjjMAfJ","sERFygZckaOm","e3aT3mEIkrYD"]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"metadata":{"id":"NAcXXqzHUiTp","colab_type":"text"},"cell_type":"markdown","source":["# ReadMe\n","\n","How to Setup:\n","\n","*   Download the Casual and Professional datasets and change the \"path_to_pro_data\" variable to the path of the professional dataset, and change the \"path_to_casual_data\" variable to the path of the casual dataset.\n","*   For both professional and casual there are two different types of data, \"Vanilla\" and \"Winrates\". \"Vanilla\" for casual only have as features a one hot encoding of the champions played and the individual player skill levels. In the professional dataset it contains a one hot encoding of the champions played and a one hot encoding of the players on each team. For \"Winrates\" it contains the previously mentioned features, but in addition the compiled winrates for champion-champion matchups and individual champion winrates.\n","*   To switch between \"Winrates\" and \"Vanilla\", change the data_type to the appropriate string. To switch between the professional and casual dataset change casual to False or True respectively.\n","*   Set the \"enable_pca\" to True if you want to run PCA on the winrates data for dimensionality reduction\n","\n","How to Run:\n","*   To run, simply set up as specified above and then run all code cells consecutively.\n","\n","Error Handling:\n","*    In the case of an error, reset the runtime and run the code cells consecutively again.\n","\n","\n"]},{"metadata":{"id":"DVwPhAYKnkrl","colab_type":"text"},"cell_type":"markdown","source":["## Edit Program Behavior Here"]},{"metadata":{"id":"2Fp5uVuFkoGU","colab_type":"code","colab":{}},"cell_type":"code","source":["# EDIT PROGRAM HERE\n","mount_drive = True # enable if google drive must be mounted (if you store the data on Google Drive)\n","path_to_pro_data = \"/content/gdrive/Team Drives/CIS 520/professional/\"  # pro data folder must be separated in train and test folders just like the zip file\n","path_to_casual_data = \"/content/gdrive/Team Drives/CIS 520/casual/\" # casual data folder must be separated in train and test folders just like the zip file\n","features_type = \"_Winrates_\" # possible toggles: _Winrates_ or _Vanilla_\n","enable_pca = True and (features_type != \"_Vanilla_\") # change the bool only, no need to run PCA for Vanilla"],"execution_count":0,"outputs":[]},{"metadata":{"id":"AE1yEPa9Dpa0","colab_type":"text"},"cell_type":"markdown","source":["#Program Setup"]},{"metadata":{"id":"45xeB0Ft3Ggr","colab_type":"code","colab":{}},"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from sklearn import preprocessing\n","from sklearn.model_selection import train_test_split\n","from sklearn import metrics\n","import seaborn as sns\n","import matplotlib.pyplot as plt \n","from sklearn.model_selection import GridSearchCV\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import confusion_matrix\n","from sklearn.svm import SVC\n","from sklearn.model_selection import learning_curve\n","from sklearn.model_selection import ShuffleSplit\n","from sklearn.model_selection import validation_curve\n","from sklearn.decomposition import PCA\n","import time\n","\n","def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n","                        n_jobs=None, train_sizes=np.linspace(.1, 1.0, 5)):\n","    plt.figure()\n","    plt.title(title)\n","    if ylim is not None:\n","        plt.ylim(*ylim)\n","    plt.xlabel(\"Training examples\")\n","    plt.ylabel(\"Score\")\n","    train_sizes, train_scores, test_scores = learning_curve(\n","        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n","    train_scores_mean = np.mean(train_scores, axis=1)\n","    train_scores_std = np.std(train_scores, axis=1)\n","    test_scores_mean = np.mean(test_scores, axis=1)\n","    test_scores_std = np.std(test_scores, axis=1)\n","    plt.grid()\n","\n","    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n","                     train_scores_mean + train_scores_std, alpha=0.1,\n","                     color=\"r\")\n","    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n","                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n","    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n","             label=\"Training score\")\n","    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n","             label=\"Cross-validation score\")\n","\n","    plt.legend(loc=\"best\")\n","    return plt\n","  \n","def plot_valid_curve(estimator, title, X, y, ylim=None, param_name=\"gamma\",\n","                      n_jobs=None, param_range = np.logspace(-6, -1, 5), y_lim=(0.0, 1.1), train_sizes=np.linspace(.1, 1.0, 5), cv=5):\n","  train_scores, test_scores = validation_curve(estimator, X, np.ravel(y), param_name=param_name, param_range=param_range,\n","      cv=cv, scoring=\"accuracy\", n_jobs=n_jobs)\n","\n","  train_scores_mean = np.mean(train_scores, axis=1)\n","  train_scores_std = np.std(train_scores, axis=1)\n","  test_scores_mean = np.mean(test_scores, axis=1)\n","  test_scores_std = np.std(test_scores, axis=1)\n","\n","\n","  plt.title(title)\n","  plt.xlabel(param_name)\n","  plt.ylabel(\"Score\")\n","  plt.ylim(*ylim)\n","  lw = 2\n","  plt.grid()\n","  plt.plot(param_range, train_scores_mean, label=\"Training score\",\n","               color=\"darkorange\", lw=lw)\n","  plt.fill_between(param_range, train_scores_mean - train_scores_std,\n","                   train_scores_mean + train_scores_std, alpha=0.2,\n","                   color=\"darkorange\", lw=lw)\n","  plt.plot(param_range, test_scores_mean, label=\"Cross-validation score\",\n","               color=\"navy\", lw=lw)\n","  plt.fill_between(param_range, test_scores_mean - test_scores_std,\n","                   test_scores_mean + test_scores_std, alpha=0.2,\n","                   color=\"navy\", lw=lw)\n","  plt.legend(loc=\"best\")\n","  return plt"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Aa4AgJmUktUy","colab_type":"code","colab":{}},"cell_type":"code","source":["if mount_drive:\n","  from google.colab import drive\n","  drive.mount('/content/gdrive')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"KB032NjjMAfJ","colab_type":"text"},"cell_type":"markdown","source":["# Data Importing"]},{"metadata":{"id":"c-2-kdKu3YFW","colab_type":"code","colab":{}},"cell_type":"code","source":["# professional data import\n","X_pro_filename_train = path_to_pro_data + \"train/Professional_Features\" + features_type + \"Train.csv\"\n","y_pro_filename_train = path_to_pro_data + \"train/Professional_Labels_Train.csv\"\n","\n","X_train_p = pd.read_csv(X_pro_filename_train)\n","y_train_p = pd.read_csv(y_pro_filename_train)\n","\n","X_pro_filename_test = path_to_pro_data + \"test/Professional_Features\" + features_type + \"Test.csv\"\n","y_pro_filename_test = path_to_pro_data + \"test/Professional_Labels_Test.csv\"\n","\n","X_test_p = pd.read_csv(X_pro_filename_test)\n","y_test_p = pd.read_csv(y_pro_filename_test)\n","\n","# casual data import\n","X_ranked_filename_train = path_to_casual_data + \"train/Casual_Features\" + features_type + \"Train.csv\"\n","y_ranked_filename_train = path_to_casual_data + \"train/Casual_Labels_Train.csv\"\n","\n","X_train_r = pd.read_csv(X_ranked_filename_train)\n","y_train_r = pd.read_csv(y_ranked_filename_train)\n","\n","X_ranked_filename_test = path_to_casual_data + \"test/Casual_Features\" + features_type + \"Test.csv\"\n","y_ranked_filename_test = path_to_casual_data + \"test/Casual_Labels_Test.csv\"\n","\n","X_test_r = pd.read_csv(X_ranked_filename_test)\n","y_test_r = pd.read_csv(y_ranked_filename_test)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"JEFwPQ4jL7zO","colab_type":"text"},"cell_type":"markdown","source":["# Professional Data"]},{"metadata":{"id":"A0SyuO3-mvw_","colab_type":"text"},"cell_type":"markdown","source":["## 1-hot encoding for categorical features + PCA"]},{"metadata":{"id":"baQAGZ926LNP","colab_type":"code","colab":{}},"cell_type":"code","source":["# merge test and train data\n","split_at = X_train_p.shape[0]\n","full_data = X_train_p.append(X_test_p)\n","\n","# convert to categorical variables\n","cat_vars = list(full_data)\n","\n","for var in cat_vars:\n","  if (\"player\" in var) or (\"winrate\" in var):\n","    continue\n","  else:\n","    full_data[var] = full_data[var].astype('category')\n","    \n","# perform 1-hot encoding on categorical data\n","for var in cat_vars:\n","  if (\"player\" in var) or (\"winrate\" in var):\n","    continue\n","  else:\n","    cat_list = pd.get_dummies(full_data[var], prefix = var) # makes every variable binary\n","    full_data = pd.concat([full_data, cat_list], axis=1)\n","\n","# drop data pre-1-hot encoding\n","full_data.drop(columns = ['blue_top', 'red_top', 'blue_jungle', 'red_jungle', 'blue_middle','red_middle', 'blue_adc', 'red_adc', 'blue_support', 'red_support'], inplace=True)\n","\n","# split into test and train according to original split\n","X_train_p_encoded = full_data[0:split_at]\n","X_test_p_encoded = full_data[split_at:full_data.shape[0]]\n","\n","# features & labels\n","X_train = X_train_p_encoded\n","y_train = y_train_p\n","X_test = X_test_p_encoded\n","y_test = y_test_p\n","\n","# feature size reduction with PCA\n","if enable_pca:\n","  components_requested = 1\n","  variance_threshold = 0.9\n","  while True:\n","    pca = PCA(n_components=components_requested)\n","    pca.fit(X_train)\n","    if np.sum(pca.explained_variance_ratio_) > variance_threshold:\n","      break\n","    else:\n","      components_requested +=1\n","  X_train = pca.transform(X_train)\n","  X_test = pca.transform(X_test)\n","  print(\"PCA Components Extracted:\", format(components_requested))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"6hn0Ff7ym5fo","colab_type":"text"},"cell_type":"markdown","source":["## SVM Algorithm (Warning: takes a while to run, lower CV fold/iterations to make it run faster)"]},{"metadata":{"id":"sERFygZckaOm","colab_type":"text"},"cell_type":"markdown","source":["### Cross Validation (tuning for F1)"]},{"metadata":{"id":"Oldzy2Vt4EDk","colab_type":"code","outputId":"cf4231ea-3ae2-47ac-d321-e707fcbfb699","executionInfo":{"status":"ok","timestamp":1556647607322,"user_tz":240,"elapsed":901628,"user":{"displayName":"Ziad Ben Hadj-Alouane","photoUrl":"","userId":"08742140045256868470"}},"colab":{"base_uri":"https://localhost:8080/","height":799}},"cell_type":"code","source":["# SVM Algorithm\n","from sklearn.svm import SVC\n","\n","# Note, linear SVM is so bad that it doesn't predict one of the labels most of the time, hence the terrible accuracy\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","# Set the parameters by cross-validation\n","tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4, 1e-5], 'C': [1, 10, 100, 1000]},\n","                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n","\n","print(\"************************** PROFESSIONAL DATA SVM ************************* \")\n","print(\"************************************************************************** \")\n","print(\"# Tuning SVM hyper-parameters for F1 Measure\")\n","print()\n","\n","clf = GridSearchCV(SVC(cache_size=7000, max_iter=5000), tuned_parameters, cv=5,\n","                   scoring='f1')\n","clf.fit(X_train, np.ravel(y_train))\n","\n","print(\"Best parameters set found on development set:\")\n","print()\n","print(clf.best_params_)\n","print()\n","print(\"Grid scores on development set:\")\n","print()\n","means = clf.cv_results_['mean_test_score']\n","stds = clf.cv_results_['std_test_score']\n","for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n","    print(\"%0.3f (+/-%0.03f) for %r\"\n","          % (mean, std * 2, params))\n","print()\n","\n","\n","print(\"The model is trained on the full development set.\")\n","print(\"The scores are computed on the full evaluation set.\")\n","print()\n","\n","print('Accuracy of chosen model:')\n","print(clf.score(X_test, y_test))\n","print(\"Detailed classification report:\")\n","print()\n","y_true, y_pred = y_test, clf.predict(X_test)\n","print(classification_report(y_true, y_pred))\n","print()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["************************** PROFESSIONAL DATA SVM ************************* \n","************************************************************************** \n","# Tuning SVM hyper-parameters for F1 Measure\n","\n","Best parameters set found on development set:\n","\n","{'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n","\n","Grid scores on development set:\n","\n","0.704 (+/-0.001) for {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n","0.704 (+/-0.001) for {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'}\n","0.704 (+/-0.001) for {'C': 1, 'gamma': 1e-05, 'kernel': 'rbf'}\n","0.693 (+/-0.017) for {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n","0.704 (+/-0.001) for {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n","0.704 (+/-0.001) for {'C': 10, 'gamma': 1e-05, 'kernel': 'rbf'}\n","0.611 (+/-0.014) for {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n","0.692 (+/-0.018) for {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}\n","0.704 (+/-0.001) for {'C': 100, 'gamma': 1e-05, 'kernel': 'rbf'}\n","0.583 (+/-0.030) for {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}\n","0.613 (+/-0.013) for {'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'}\n","0.692 (+/-0.018) for {'C': 1000, 'gamma': 1e-05, 'kernel': 'rbf'}\n","0.596 (+/-0.025) for {'C': 1, 'kernel': 'linear'}\n","0.526 (+/-0.061) for {'C': 10, 'kernel': 'linear'}\n","0.526 (+/-0.061) for {'C': 100, 'kernel': 'linear'}\n","0.526 (+/-0.061) for {'C': 1000, 'kernel': 'linear'}\n","\n","The model is trained on the full development set.\n","The scores are computed on the full evaluation set.\n","\n","Accuracy of chosen model:\n","0.7154318074563474\n","Detailed classification report:\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       603\n","           1       0.56      1.00      0.72       758\n","\n","   micro avg       0.56      0.56      0.56      1361\n","   macro avg       0.28      0.50      0.36      1361\n","weighted avg       0.31      0.56      0.40      1361\n","\n","\n"],"name":"stdout"}]},{"metadata":{"id":"tgqSXmyDkffT","colab_type":"text"},"cell_type":"markdown","source":["### Optimal Models in Each Case"]},{"metadata":{"colab_type":"code","outputId":"402a9e78-80ca-4b86-b6f3-d5c99651404f","executionInfo":{"status":"ok","timestamp":1556650129773,"user_tz":240,"elapsed":11216,"user":{"displayName":"Ziad Ben Hadj-Alouane","photoUrl":"","userId":"08742140045256868470"}},"id":"XPNGsyXEIKtN","colab":{"base_uri":"https://localhost:8080/","height":88}},"cell_type":"code","source":["from sklearn.svm import SVC\n","\n","# modify these if you wish to run algo without CV\n","C_selected = 1\n","if enable_pca:\n","  C_selected = 1\n","  \n","if features_type == \"Vanilla\":\n","  C_selected = 1\n","\n","start = time.time()\n","svm_linear = SVC(kernel='linear', C=C_selected, cache_size=7000, max_iter=100000);\n","svm_linear.fit(X_train, np.ravel(y_train))\n","end = time.time()\n","print('Training Time: {:.5f}'.format(end - start))\n","y_pred = svm_linear.predict(X_test)\n","print('Accuracy of linear SVC on Pro test set: {:.5f}'.format(svm_linear.score(X_test, y_test)))\n","\n","conf_mat = confusion_matrix(y_test, y_pred)\n","print(conf_mat)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Training Time: 7.11471\n","Accuracy of linear SVC on Pro test set: 0.48273\n","[[374 229]\n"," [475 283]]\n"],"name":"stdout"}]},{"metadata":{"colab_type":"code","id":"h1QdyqzeIKtR","colab":{}},"cell_type":"code","source":["from sklearn.svm import SVC\n","\n","# modify these if you wish to run algo without CV\n","C_selected = 100\n","gamma_selected = 0.001\n","if enable_pca:\n","  C_selected = 1\n","  gamma_selected = 0.001\n","  \n","if features_type == \"Vanilla\":\n","  gamma_selected = 0.001\n","  C_selected = 1\n","\n","# train model and print accuracy\n","start = time.time()\n","svm_rbf = SVC(kernel='rbf', C=C_selected, gamma=gamma_selected, cache_size=7000, max_iter=10000)\n","svm_rbf.fit(X_train, np.ravel(y_train))\n","end = time.time()\n","print('Training Time: {:.5f}'.format(end - start))\n","y_pred = svm_rbf.predict(X_test)\n","print('Accuracy of RBF SVC on Pro test set: {:.2f}'.format(svm_rbf.score(X_test, y_test)))\n","\n","conf_mat = confusion_matrix(y_test, y_pred)\n","print(conf_mat)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"F867AVNfmCtw","colab_type":"text"},"cell_type":"markdown","source":["### Curves"]},{"metadata":{"id":"Qu4BM2IOmEFa","colab_type":"code","colab":{}},"cell_type":"code","source":["# parameters to plot\n","estimator = svm_rbf # svm_linear or svm_rbf\n","param_name = \"C\" # C or gamma\n","param_range = [1, 10, 100, 1000] # np.logspace(-6, -1, 5) or [1, 10, 100, 1000]\n","y_lim_train_curve = (0.5, 0.6)\n","y_lim_cv_curve = (0.5, 1)\n","title_train=\"Learning Curves (SVM, Linear) after Cross-Validation\"\n","title_cv=\"Validation Curve with Linear SVM (C parameter)\"\n","\n","# Learning curve SVM RBF\n","cv = ShuffleSplit(n_splits=5, test_size=0.3, random_state=0)\n","train_plot = plot_learning_curve(estimator, title=title_train, X=X_train, y=y_train, ylim=y_lim_train_curve, cv=cv, n_jobs=4)\n","train_plot.show()\n","\n","# CV curve SVM RBF\n","cv_plot = plot_valid_curve(estimator, title=title_cv, X=X_train, y=y_train, ylim=y_lim_cv_curve, cv=5, param_name=param_name,\n","                      n_jobs=1, param_range = param_range, train_sizes=np.linspace(.1, 1.0, 5))\n","cv_plot.show()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ybqLb88GMEtU","colab_type":"text"},"cell_type":"markdown","source":["# Casual Data"]},{"metadata":{"id":"leVXNan7rgwa","colab_type":"text"},"cell_type":"markdown","source":["## 1-hot encoding for categorical features + PCA"]},{"metadata":{"id":"Qf70cCVgMIn0","colab_type":"code","colab":{}},"cell_type":"code","source":["# merge train and test data\n","split_at = X_train_r.shape[0]\n","full_data = X_train_r.append(X_test_r)\n","\n","# convert to categorical variables\n","cat_vars = list(full_data)\n","\n","for var in cat_vars:\n","  if (\"skill\" in var) or (\"winrate\" in var):\n","    continue\n","  else:\n","    full_data[var] = full_data[var].astype('category')\n","    \n","# perform 1-hot encoding for categorical features\n","for var in cat_vars:\n","  if (\"skill\" in var) or (\"winrate\" in var):\n","    continue\n","  else:\n","    cat_list = pd.get_dummies(full_data[var], prefix = var) # makes every variable binary\n","    full_data = pd.concat([full_data, cat_list], axis=1)\n","\n","\n","full_data.drop(columns = ['blue_top', 'red_top', 'blue_jungle', 'red_jungle', 'blue_middle','red_middle', 'blue_adc', 'red_adc', 'blue_support', 'red_support'], inplace=True)\n","\n","# unmerge train and test data\n","X_train_r_encoded = full_data[0:split_at]\n","X_test_r_encoded = full_data[split_at:full_data.shape[0]]\n","\n","# features & labels\n","X_train = X_train_r_encoded\n","y_train = y_train_r\n","X_test = X_test_r_encoded\n","y_test = y_test_r\n","\n","\n","# feature size reduction with PCA\n","if enable_pca:\n","  components_requested = 1\n","  variance_threshold = 0.9\n","  while True:\n","    pca = PCA(n_components=components_requested)\n","    pca.fit(X_train)\n","    if np.sum(pca.explained_variance_ratio_) > variance_threshold:\n","      break\n","    else:\n","      components_requested +=1\n","      \n","  X_train = pca.transform(X_train)\n","  X_test = pca.transform(X_test)\n","  print(\"PCA Components Extracted:\", format(components_requested))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"qkwWsd2MrlTA","colab_type":"text"},"cell_type":"markdown","source":["## SVM Algorithm"]},{"metadata":{"id":"e3aT3mEIkrYD","colab_type":"text"},"cell_type":"markdown","source":["### Cross-Validation (tuning for F1)"]},{"metadata":{"colab_type":"code","id":"WiQegKxEMWam","outputId":"48102ac0-b7d8-4536-c46f-c32720bc5410","executionInfo":{"status":"error","timestamp":1556655261457,"user_tz":240,"elapsed":5932,"user":{"displayName":"Ziad Ben Hadj-Alouane","photoUrl":"","userId":"08742140045256868470"}},"colab":{"base_uri":"https://localhost:8080/","height":458}},"cell_type":"code","source":["# SVM Algorithm\n","from sklearn.svm import SVC\n","\n","# Set the parameters by cross-validation\n","tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4], 'C': [1, 5, 10, 100, 1000]},\n","                    {'kernel': ['linear'], 'C': [1, 5, 10, 100, 1000]}]\n","\n","print(\"************************** CASUAL DATA SVM ******************************* \")\n","print(\"************************************************************************** \")\n","print(\"# Tuning hyper-parameters for F1 Measure\")\n","print()\n","\n","clf = GridSearchCV(SVC(cache_size=7000, max_iter=50000), tuned_parameters, cv=5,\n","                   scoring='f1')\n","clf.fit(X_train, np.ravel(y_train))\n","\n","print(\"Best parameters set found on development set:\")\n","print()\n","print(clf.best_params_)\n","print()\n","print(\"Grid scores on development set:\")\n","print()\n","means = clf.cv_results_['mean_test_score']\n","stds = clf.cv_results_['std_test_score']\n","for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n","    print(\"%0.3f (+/-%0.03f) for %r\"\n","          % (mean, std * 2, params))\n","print()\n","\n","\n","print(\"The model is trained on the full development set.\")\n","print(\"The scores are computed on the full evaluation set.\")\n","print()\n","\n","print('Accuracy of chosen model:')\n","print(clf.score(X_test, y_test))\n","print(\"Detailed classification report:\")\n","print()\n","y_true, y_pred = y_test, clf.predict(X_test)\n","print(classification_report(y_true, y_pred))\n","print()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["************************** CASUAL DATA SVM ******************************* \n","************************************************************************** \n","# Tuning hyper-parameters for F1 Measure\n","\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-210-48ab2f2cebb0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m clf = GridSearchCV(SVC(cache_size=7000, max_iter=50000), tuned_parameters, cv=5,\n\u001b[1;32m     13\u001b[0m                    scoring='f1')\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Best parameters set found on development set:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    720\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1189\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1191\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    709\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 711\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m                 \u001b[0mall_candidate_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    915\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m         \u001b[0;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36m_dense_fit\u001b[0;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[1;32m    269\u001b[0m                 \u001b[0mcache_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoef0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m                 \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m                 max_iter=self.max_iter, random_seed=random_seed)\n\u001b[0m\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_warn_from_fit_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"metadata":{"id":"F5IMsBF_sUnS","colab_type":"text"},"cell_type":"markdown","source":["### With Optimal Parameters in Each Case"]},{"metadata":{"id":"HLrUF8hNxqCc","colab_type":"code","colab":{}},"cell_type":"code","source":["# modify these if you wish to run algo without CV\n","C_selected = 1\n","if enable_pca:\n","  C_selected = 1\n","  \n","if features_type == \"_Vanilla_\":\n","  C_selected = 1\n","\n","# train model and print accuracy\n","start = time.time()\n","svm_rbf = SVC(kernel='linear', C=C_selected, cache_size=7000, max_iter=50000)\n","svm_rbf.fit(X_train, np.ravel(y_train))\n","end = time.time()\n","print('Training Time: {:.5f}'.format(end - start))\n","y_pred = svm_rbf.predict(X_test)\n","print('Accuracy of Linear SVC on Casual test set: {:.5f}'.format(svm_rbf.score(X_test, y_test)))\n","\n","conf_mat = confusion_matrix(y_test, y_pred)\n","print(conf_mat)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"-j26Vz6nzc5s","colab_type":"code","colab":{}},"cell_type":"code","source":["from sklearn.svm import SVC\n","\n","# modify these if you wish to run algo without CV\n","C_selected = 100\n","gamma_selected = 0.001\n","if enable_pca:\n","  C_selected = 5\n","  gamma_selected = 0.0001\n","  \n","if features_type == \"_Vanilla_\":\n","  gamma_selected = 0.0001\n","  C_selected = 5\n","\n","# train model and print accuracy\n","start = time.time()\n","svm_rbf = SVC(kernel='rbf', C=C_selected, gamma=gamma_selected, cache_size=7000, max_iter=10000)\n","svm_rbf.fit(X_train, np.ravel(y_train))\n","end = time.time()\n","print('Training Time: {:.5f}'.format(end - start))\n","y_pred = svm_rbf.predict(X_test)\n","print('Accuracy of RBF SVC on Pro test set: {:.5f}'.format(svm_rbf.score(X_test, y_test)))\n","\n","conf_mat = confusion_matrix(y_test, y_pred)\n","print(conf_mat)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"wXVI4gfhl28r","colab_type":"text"},"cell_type":"markdown","source":["### Curves"]},{"metadata":{"id":"iiADoWhA4ANu","colab_type":"code","colab":{}},"cell_type":"code","source":["# parameters to plot\n","estimator = svm_rbf # svm_linear or svm_rbf\n","param_name = \"gamma\" # C or gamma\n","param_range = np.logspace(-6, -1, 5) # or [1, 10, 100, 1000]\n","y_lim_train_curve = (0.92, 0.97)\n","y_lim_cv_curve = (0.5, 1)\n","title_train=\"Learning Curves (SVM, RBF) after Cross-Validation\"\n","title_cv=\"Validation Curve with RBF SVM (gamma parameter)\"\n","\n","# Learning curve SVM RBF\n","cv = ShuffleSplit(n_splits=5, test_size=0.3, random_state=0)\n","train_plot = plot_learning_curve(estimator, title=title_train, X=X_train, y=y_train, ylim=y_lim_train_curve, cv=cv, n_jobs=4)\n","train_plot.show()\n","\n","# CV curve SVM RBF\n","cv_plot = plot_valid_curve(estimator, title=title_cv, X=X_train, y=y_train, ylim=y_lim_cv_curve, cv=5, param_name=param_name,\n","                      n_jobs=1, param_range = param_range, train_sizes=np.linspace(.1, 1.0, 5))\n","cv_plot.show()"],"execution_count":0,"outputs":[]}]}